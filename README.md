# SQL Data Cleaning Project - Layoffs Data 2022

This project involves cleaning a dataset of worldwide layoffs that occurred in 2022. The data is sourced from Kaggle and includes information on company names, industries, total laid-off employees, dates, and more. The purpose of this project is to ensure the data is clean and ready for analysis by removing duplicates, standardizing values, and handling nulls appropriately.

## Project Overview

The main steps involved in this data cleaning process are:

1. **Create a Staging Table**: To keep the original data intact, we create a staging table for all cleaning operations.
2. **Remove Duplicates**: Identify and remove duplicate rows.
3. **Standardize Data**: Correct inconsistencies and standardize data values.
4. **Handle Null Values**: Review and address null values where necessary.
5. **Remove Unnecessary Data**: Remove any columns or rows that are not needed for analysis.

## Data Source

The dataset used in this project can be found on Kaggle: [Layoffs Dataset 2022](https://www.kaggle.com/datasets/swaptr/layoffs-2022)

## Files

- `layoffs.csv`: The original dataset.
- `cleaning.sql`: The SQL script used for cleaning the data.

## SQL Script

The SQL script follows best practices for data cleaning and transformation, ensuring the dataset is reliable for subsequent analysis.

## Usage

1. Load the original dataset into a database.
2. Run the SQL script to clean the data.
3. Use the cleaned data for your analysis or data science projects.

## Requirements

- MySQL or any other compatible SQL database.
- Basic understanding of SQL for running the script.

## Author

This project was carried out by Bairavan. You can connect with me on [LinkedIn](www.linkedin.com/in/bairavan7904569673) or check out my other projects on [GitHub](your-github-profile).
